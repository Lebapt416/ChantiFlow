"""
API FastAPI pour servir le mod√®le de pr√©diction de dur√©e de chantier
Charge le mod√®le PyTorch et expose une route POST /predict
"""

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field
import torch
import torch.nn as nn
from pathlib import Path
import numpy as np

# Import du mod√®le (m√™me structure que train_model.py)
class ChantierPredictor(nn.Module):
    """R√©seau de neurones simple pour pr√©dire la dur√©e d'un chantier"""
    
    def __init__(self):
        super(ChantierPredictor, self).__init__()
        self.fc = nn.Linear(2, 1)
    
    def forward(self, x):
        return self.fc(x)


# Mod√®le Pydantic pour la validation des entr√©es
class ChantierInput(BaseModel):
    """Sch√©ma de validation pour les donn√©es d'entr√©e"""
    nombre_taches: int = Field(..., ge=1, le=100, description="Nombre de t√¢ches du chantier (entre 1 et 100)")
    complexite: float = Field(..., ge=1.0, le=10.0, description="Niveau de complexit√© du chantier (entre 1.0 et 10.0)")


# Mod√®le Pydantic pour la r√©ponse
class ChantierPrediction(BaseModel):
    """Sch√©ma de r√©ponse pour la pr√©diction"""
    duree_estimee: float = Field(..., description="Dur√©e estim√©e du chantier en jours")


# Initialiser FastAPI
app = FastAPI(
    title="ChantiFlow Prediction API",
    description="API pour pr√©dire la dur√©e d'un chantier bas√©e sur le nombre de t√¢ches et la complexit√©",
    version="1.0.0"
)

# Configurer CORS pour permettre les requ√™tes depuis le front-end
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # En production, remplacer par les origines sp√©cifiques
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Variable globale pour stocker le mod√®le
model = None
mean_values = None
std_values = None


@app.on_event("startup")
async def load_model():
    """
    Charge le mod√®le PyTorch au d√©marrage de l'API
    """
    global model, mean_values, std_values
    
    model_path = Path("ml/predictor.pt")
    
    if not model_path.exists():
        raise FileNotFoundError(
            f"Le mod√®le {model_path} n'existe pas. "
            "Veuillez d'abord ex√©cuter train_model.py pour entra√Æner le mod√®le."
        )
    
    try:
        # Cr√©er le mod√®le
        model = ChantierPredictor()
        
        # Charger les poids sauvegard√©s
        checkpoint = torch.load(model_path, map_location='cpu')
        model.load_state_dict(checkpoint['model_state_dict'])
        
        # Mettre le mod√®le en mode √©valuation
        model.eval()
        
        # Valeurs de normalisation (doivent correspondre √† celles utilis√©es lors de l'entra√Ænement)
        # Ces valeurs devraient √™tre sauvegard√©es avec le mod√®le en production
        mean_values = torch.tensor([25.0, 5.5])  # Moyennes approximatives
        std_values = torch.tensor([12.0, 2.5])   # √âcart-types approximatifs
        
        print(f"‚úÖ Mod√®le charg√© depuis {model_path}")
        print(f"üìä Mod√®le pr√™t √† faire des pr√©dictions")
        
    except Exception as e:
        print(f"‚ùå Erreur lors du chargement du mod√®le: {e}")
        raise


@app.get("/")
async def root():
    """Route de base pour v√©rifier que l'API fonctionne"""
    return {
        "message": "ChantiFlow Prediction API",
        "status": "running",
        "endpoints": {
            "predict": "/predict (POST)"
        }
    }


@app.get("/health")
async def health_check():
    """Route de sant√© pour v√©rifier l'√©tat de l'API"""
    return {
        "status": "healthy",
        "model_loaded": model is not None
    }


@app.post("/predict", response_model=ChantierPrediction)
async def predict_chantier_duree(input_data: ChantierInput):
    """
    Route POST pour pr√©dire la dur√©e d'un chantier
    
    Args:
        input_data: Donn√©es d'entr√©e contenant nombre_taches et complexite
    
    Returns:
        ChantierPrediction: Dur√©e estim√©e du chantier en jours
    """
    if model is None:
        raise HTTPException(
            status_code=503,
            detail="Le mod√®le n'est pas charg√©. Veuillez r√©essayer plus tard."
        )
    
    try:
        # Convertir les entr√©es en tenseur
        input_tensor = torch.FloatTensor([[input_data.nombre_taches, input_data.complexite]])
        
        # Normaliser les entr√©es (m√™me normalisation que lors de l'entra√Ænement)
        if mean_values is not None and std_values is not None:
            input_tensor = (input_tensor - mean_values) / (std_values + 1e-8)
        
        # Faire la pr√©diction
        with torch.no_grad():
            prediction = model(input_tensor)
            duree_estimee = prediction.item()
        
        # S'assurer que la dur√©e est positive
        duree_estimee = max(1.0, duree_estimee)
        
        return ChantierPrediction(duree_estimee=round(duree_estimee, 2))
        
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"Erreur lors de la pr√©diction: {str(e)}"
        )


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)

